{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageDraw\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and convert to greyscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the image and convert it to greyscale since we are asked to convolve on greyscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_np(x):\n",
    "    \"\"\"\n",
    "    Display a numpy array as an image\n",
    "    \"\"\"\n",
    "    result = Image.fromarray(x.astype('uint8'))\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(x):\n",
    "    x = Image.open('test-images/' + x).convert(\"L\")\n",
    "    x = np.array(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list(imgs):\n",
    "    return [read_image(im) for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = read_image('music1.png')\n",
    "# pixels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_range(x): return (np.min(x), np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_range(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some test kernels**\n",
    "\n",
    "- a = identity\n",
    "- b = box blur\n",
    "- c = horizontal derivative\n",
    "- d = gaussian\n",
    "- e = sharpening\n",
    "- f = derivative of gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((3,3))\n",
    "a[1,1] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.ones((3,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [-1.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.zeros((3,3))\n",
    "c[1,0], c[1,2] = -1, 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.003, 0.013, 0.022, 0.013, 0.003],\n",
       "       [0.013, 0.059, 0.097, 0.059, 0.013],\n",
       "       [0.022, 0.097, 0.159, 0.097, 0.022],\n",
       "       [0.013, 0.059, 0.097, 0.059, 0.013],\n",
       "       [0.003, 0.013, 0.022, 0.013, 0.003]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([[0.003,0.013,0.022,0.013,0.003],\n",
    "             [0.013,0.059,0.097,0.059,0.013],\n",
    "             [0.022,0.097,0.159,0.097,0.022],\n",
    "             [0.013,0.059,0.097,0.059,0.013],\n",
    "             [0.003,0.013,0.022,0.013,0.003]])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.003, -0.013, -0.022, -0.013, -0.003],\n",
       "       [-0.013, -0.059, -0.097, -0.059, -0.013],\n",
       "       [-0.022, -0.097,  1.641, -0.097, -0.022],\n",
       "       [-0.013, -0.059, -0.097, -0.059, -0.013],\n",
       "       [-0.003, -0.013, -0.022, -0.013, -0.003]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vary the value of alpha\n",
    "e = np.zeros((5,5))\n",
    "e[1:4,1:4] = a\n",
    "alpha = 0.8 + 1\n",
    "e = e * alpha - d\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [ 0.   , -0.097,  0.   ,  0.097,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.zeros((5,5))\n",
    "f[1:4,1:4] = c\n",
    "f = f * d\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(x, kernel):\n",
    "    \"\"\"\n",
    "    Create a new numpy array with all values 255 and then add the image in between\n",
    "    i/p: image, kernel\n",
    "    o/p: padded_kernelx\n",
    "    \"\"\"\n",
    "    to_add = kernel.shape[0] - 1\n",
    "    padded_image = np.full((x.shape[0] + to_add, x.shape[1] + to_add), 255)\n",
    "    t = to_add // 2\n",
    "    padded_image[t: padded_image.shape[0] - t, t: padded_image.shape[1] - t] = x\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 1276)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pad_image(pixels, a)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert p.shape == (pixels.shape[0] + a.shape[0] - 1, pixels.shape[1] + a.shape[0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_np(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(image, kernel, div = 1, clip = True):\n",
    "    \"\"\"\n",
    "    Applies 2d convolution on a 2d image. Also works with rectangular kernels\n",
    "    \"\"\"\n",
    "\n",
    "    # number of rows and columns of the kernel\n",
    "    r = kernel.shape[0]\n",
    "    c = kernel.shape[1]\n",
    "\n",
    "    # initialize a canvas for the output with 255s. We will fill values in this\n",
    "    output = np.full(image.shape, 255)\n",
    "    for i in range(image.shape[0] - r - 1):\n",
    "        for j in range(image.shape[1] - c - 1):\n",
    "            output[i][j] = np.sum(kernel * image[i:i+r, j:j+c]) / div\n",
    "    if clip: np.clip(output, 0, 255, out = output)\n",
    "    return output\n",
    "    #display_np(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d(p, a)\n",
    "# conv2d(p, b, 9)\n",
    "# conv2d(p, c)\n",
    "# conv2d(p, d)\n",
    "# conv2d(p, e)\n",
    "# conv2d(p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel = np.array([[-1, 0, 1],\n",
    "                 [-2, 0, 2],\n",
    "                 [-1, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d(p, sobel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"\".\n"
     ]
    }
   ],
   "source": [
    "%ls test-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = read_list(['template1.png', 'template2.png', 'template3.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.full(p.shape, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(y):\n",
    "    \"\"\"\n",
    "    Takes a number y and returns a threshold eg 3542, thresh = 3000\n",
    "    eg2 16258325 thresh 10000000\n",
    "    \"\"\"\n",
    "    y = [int(i) for i in str(y)]\n",
    "    thresh = y[0] * 10 ** (len(y) - 1)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(x, vals):\n",
    "    idxs1, idxs2 = np.array([]), np.array([])\n",
    "    \n",
    "    for v in vals:\n",
    "        v_idxs = np.where(x == v)\n",
    "        idxs1 = np.append(idxs1 ,v_idxs[0])\n",
    "        idxs2 = np.append(idxs2 ,v_idxs[1])\n",
    "    return idxs1, idxs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_match(templates, padded_im):\n",
    "    \"\"\"\n",
    "    Takes a list of templates and an image and returns the matched template\n",
    "    \"\"\"\n",
    "    # also try the other images in the test_images\n",
    "    # esp the big ranch image or something\n",
    "    \n",
    "    \n",
    "    pix = Image.fromarray(padded_im.astype('uint8'))\n",
    "    img = ImageDraw.Draw(pix)  \n",
    "    \n",
    "    for template in templates:\n",
    "        # apply the hamming distance forumula\n",
    "        op = conv2d(padded_im, template, 1, False) + conv2d(255 - padded_im, 255 - template, 1, False)\n",
    "\n",
    "        # get the min and maximum value\n",
    "        x,y = check_range(op)    \n",
    "\n",
    "        # find threshold, eg if max val is 583 thresh = 500\n",
    "        thresh = find_threshold(y)\n",
    "\n",
    "        # get all the values above thresh\n",
    "        temp_op = op[op > thresh]\n",
    "\n",
    "        # get indexes of the values above thresh\n",
    "        idxs1, idxs2 = get_indexes(op, temp_op)\n",
    "\n",
    "        tr, tc = int(template.shape[0]), int(template.shape[1])\n",
    "        cr, cc = int(canvas.shape[0]), int(canvas.shape[1])\n",
    "\n",
    "        # if the template is not going out of the canvas, plot it\n",
    "        for r,c in zip(idxs1, idxs2):\n",
    "            r, c = int(r), int(c)\n",
    "            if r+tr < cr and c+tc < cc:\n",
    "                canvas[r:r+tr, c:c+tc] = padded_im[r:r+tr, c:c+tc]\n",
    "#         print(\"One template done\")\n",
    "#                 img.rectangle([(r,c),(r+tr,c+tc)],fill=None,outline=\"green\")\n",
    "#     pix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_match(templates,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op = conv2d(p, tmp3, 1, False) + conv2d(255 - p, 255 - tmp3, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = check_range(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_np(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(image, kernel, div = 1):\n",
    "    \"\"\"\n",
    "    Performs 1d convolution on an image\n",
    "    \"\"\"\n",
    "    \n",
    "    im = copy.deepcopy(image.flatten())\n",
    "    k = copy.deepcopy(kernel.flatten())\n",
    "\n",
    "    size = len(k)\n",
    "    to_remove = len(k) - 1\n",
    "    \n",
    "    output = np.full((im.shape), 255)\n",
    "    for i in range(len(im) - to_remove):\n",
    "        output[i] = np.sum(k * im[i:i+size]) / div\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = np.array([1,2,1])\n",
    "h2 = np.array([-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = conv1d(p, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conv1d(tmp, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-765, 765)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_range(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(result, 0, 255, out = result)\n",
    "check_range(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 1276)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reshape(p.shape)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_np(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.new('RGB', (500, 300), (128, 128, 128))\n",
    "# pix = Image.fromarray(pixels.astype('uint8'))\n",
    "# img1 = ImageDraw.Draw(pix)   \n",
    "# img1.rectangle([(0,20),(40,100)], fill =None, outline =\"red\")\n",
    "# img1.rectangle([(40,100), (60, 200)], fill =None, outline =\"green\") \n",
    "# pix.show() \n",
    "# draw = ImageDraw.Draw(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw.line(((200, 100),(300, 200)),width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [2],\n",
       "        [1]]), array([[1, 2, 1]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a sobel operator\n",
    "def sobel(mat):\n",
    "    \n",
    "    arr1 = []\n",
    "    arr2 = []\n",
    "    \n",
    "    #Finding the supposed first matrix\n",
    "    arr1.append(np.gcd.reduce(mat[0,:]))\n",
    "    arr1.append(np.gcd.reduce(mat[1,:]))\n",
    "    arr1.append(np.gcd.reduce(mat[2,:]))\n",
    "    \n",
    "    #Finding the supposed second matrix\n",
    "    arr2.append(np.gcd.reduce(mat[:,0]))\n",
    "    arr2.append(np.gcd.reduce(mat[:,1]))\n",
    "    arr2.append(np.gcd.reduce(mat[:,2]))\n",
    "    \n",
    "    #Reshaping the two matrices\n",
    "    arr1 = np.array(arr1).reshape(3,1)\n",
    "    arr2 = np.array(arr2).reshape(1,3)\n",
    "    \n",
    "    #Checking whether the matrices are accurate\n",
    "    bool_mat = np.equal(np.matmul(arr1, arr2), mat)\n",
    "    \n",
    "    if((np.logical_not(np.bitwise_xor(bool_mat[0,:],[False, False, False]))).all()):\n",
    "        arr1[0] = np.negative(arr1[0])\n",
    "        \n",
    "    elif((np.logical_not(np.bitwise_xor(bool_mat[1,:],[False, False, False]))).all()):\n",
    "        arr1[1] = np.negative(arr1[1])\n",
    "        \n",
    "    elif((np.logical_not(np.bitwise_xor(bool_mat[2,:],[False, False, False]))).all()):\n",
    "        arr1[2] = np.negative(arr1[2])\n",
    "        \n",
    "    return arr1, arr2\n",
    "\n",
    "mat = np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "sobel(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21e528c59e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pixels = read_image('music1.png')\n",
    "\n",
    "kernel = np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "\n",
    "plt.imshow(conv2d(pixels, kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 1274)\n"
     ]
    }
   ],
   "source": [
    "#Using sobel kernels\n",
    "sobel_kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "#Convolving the image\n",
    "conv_img = conv2d(pixels, kernel_1)\n",
    "\n",
    "#plt.imshow(conv_img)\n",
    "\n",
    "print(pixels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 1274)\n",
      "(231, 1274)\n"
     ]
    }
   ],
   "source": [
    "#Creating an empty edge maps\n",
    "T = []\n",
    "\n",
    "#Iterating through the image\n",
    "for i in conv_img:\n",
    "    for j in i:\n",
    "        \n",
    "        #Checking if pixel value is 0 or not\n",
    "        if(j == 0):\n",
    "            T.append(0)\n",
    "        else:\n",
    "            T.append(1)\n",
    "            \n",
    "#Converting edge map to numpy array and reshaping it to the convolved image\n",
    "T = np.array(T).reshape(conv_img.shape)\n",
    "\n",
    "#Creating the other edge map\n",
    "I = np.copy(T)\n",
    "\n",
    "#Checking the shape of the edge maps\n",
    "print(T.shape)\n",
    "print(I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to calculate distance\n",
    "def calc_dist(a, b, c, d):\n",
    "    \n",
    "    #Calculating distance\n",
    "    dist = math.sqrt(abs(((a - c)*(a - c)) + ((b - d)*(b - d))))\n",
    "    \n",
    "    return dist\n",
    "\n",
    "#Retrieving the number of rows and columns in the image\n",
    "row, col = conv_img.shape\n",
    "\n",
    "#Creating an array to store distances\n",
    "D = []\n",
    "\n",
    "#Iterating through the image pixels\n",
    "for p in range(0,row):\n",
    "    for q in range(0,col):\n",
    "        \n",
    "        #Creating a temporary array\n",
    "        temp = []\n",
    "        \n",
    "        #Iterating through the edge pixels\n",
    "        for i in range(0,row):\n",
    "            for j in range(0,col):\n",
    "                if(conv_img[i][j] != 0):\n",
    "                    \n",
    "                    #Calculating distance and storing it in temp\n",
    "                    dist = calc_dist(p, q, i, j)\n",
    "                    temp.append(dist)\n",
    "                    \n",
    "        #Converting the temporary array to a numpy array\n",
    "        temp = np.array(temp)\n",
    "        \n",
    "        #Finding the smallest distance and storing it in D\n",
    "        min_dist = np.min(temp)\n",
    "        D.append(min_dist)\n",
    "        \n",
    "        print(p,q)\n",
    "        \n",
    "#Reshaping D to that of the image\n",
    "D = np.array(D).reshape(conv_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
